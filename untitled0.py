# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W7MiOHOUecdxtHZU74JnnmAnLFRIt00I
"""

# python libraries
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# print(x_train.shape, x_train.min())

i = 3
plt.imshow(x_train[i]), y_train[i]

# Preproccessing
images = x_train / 255.0
print(images.min(), images.max())
labels = pd.get_dummies(y_train)

i = 1
y_train[i], np.array(labels[i])

from tensorflow.keras import layers, Sequential

input_dim = 28 * 28
model = Sequential([
    layers.Flatten(),
    layers.Dense(512, activation="relu"),
    layers.Dense(256, activation="relu"),
    layers.Dense(128, activation="relu"),
    layers.Dense(64, activation="relu"),
    layers.Dense(10, activation="softmax")
])

model.compile(optimizer="adam", loss=tf.losses.CategoricalCrossentropy(), metrics=["accuracy"])

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(patience=2)
history = model.fit(images, labels, batch_size=128, epochs=10_000, validation_split=0.3, callbacks=[early_stop])

pd.DataFrame(history.history).plot()

test_images = x_test / 255.0
test_labels = pd.get_dummies(y_test)

predictions = model.predict(test_images)
predictions = np.argmax(predictions, axis=1)
np.mean(np.equal(predictions, y_test))

from sklearn.metrics import confusion_matrix
import seaborn as sns

mat = confusion_matrix(y_test, predictions)

sns.heatmap(mat, annot=True)